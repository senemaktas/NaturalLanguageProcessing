{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Natural Language Processing- 1\n\nNatural language processing is a very popular field of study today. It can be defined as the processing and analysis of natural spoken languages with today's technology and methods. Various applications are developed. Some NLP use cases can be listed as follows:\n1. Sentiment analysis\n2. Text classification\n3. Machine translation\n4. Question answering (chat-bot)\n5. Text summarization and so on ...\n\nFor NLP tasks, we will use the Python **NLTK (Natural Language Toolkit)** package. This package can be defined as: platform to work with human language data. \n\n* Install NLTK : `pip3 install nltk` \n* Go to this page and download package : `https://pypi.org/project/nltk/`\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import nltk  #import nltk package\nprint(nltk.__version__)  #check package version\n#install the necessary datasets/models for specific functions to work.Like:'popular'\nnltk.download(‘popular’)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tokenization process is performs the process of dividing the string of data into substrings.\nfrom nltk.tokenize import word_tokenize\nprint(word_tokenize(\"Hi, this is my first example with NLP.\"))","execution_count":2,"outputs":[{"output_type":"stream","text":"['Hi', ',', 'this', 'is', 'my', 'first', 'example', 'with', 'NLP', '.']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Word root finding is a common process in NLP. The root finding process is called word stemmer. \n#Finding roots can be done with the following class.The process is based on the Porter Stemmer algorithm.\n\nfrom nltk.stem.porter import PorterStemmer\nrootWord = PorterStemmer()\nprint(rootWord.stem(\"going\"))\nprint(rootWord.stem(\"constitues\"))","execution_count":4,"outputs":[{"output_type":"stream","text":"go\nconstitu\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"* Lemmatization performs the converting a word to its base. It can be said that it is more careful in finding the word base compared to Stemming. Because we should define the \"part-of-speech\" (POS) tag for the word. In other words, it is the definition of words as noun, verb, adjective, adverb etc.\n\n* We can also find tags like in the second example. First break the string into substrings, then find the word base."},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tag import pos_tag\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nrootWord=WordNetLemmatizer()\nprint(rootWord.lemmatize('constitutes','v'))\n\nsample = \"Hi, this is my first example with NLP.\"\nprint(pos_tag(word_tokenize(sample)))","execution_count":6,"outputs":[{"output_type":"stream","text":"constitute\n[('Hi', 'NNP'), (',', ','), ('this', 'DT'), ('is', 'VBZ'), ('my', 'PRP$'), ('first', 'JJ'), ('example', 'NN'), ('with', 'IN'), ('NLP', 'NNP'), ('.', '.')]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"* When working with data, we can say that the first thing to do is \"data cleaning\". The first cleanup for text data is to remove punctuation marks. These are called **\"punctuations\".** The defined punctuation marks in the first code block below can be observed. \n\n* Another data cleaning step is removing **stop words** for text data. Stop-words can define as  low-meaning word for text data. They are very intense in the text and may negatively affect the actual desired process due to the possibility of high frequencies. It is important to perform this process, especially for sentiment analysis. You can see basic stop-words process in the second code block below."},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nprint(string.punctuation) # !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n\nsample= \"Remove ~ punctuations , from,  here * ? \" # example string\nno_punctuation = \"\" # this will contain the new string without punctuation.\n\nfor i in sample:    # divide string and take one by one \n    if i not in string.punctuation:  # control each , if its not punctuation, include new string\n        no_punctuation += i\n    else:  # if its punctuation just pass \n        pass\n    \nprint(no_punctuation)  # print new string","execution_count":16,"outputs":[{"output_type":"stream","text":"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\nRemove  punctuations  from  here   \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nprint(stopwords.words('english')) # print list of \"stop-words in English language\n\nsample = \"Remove the stop words from the sentence. It will be clearer.\" # example string\n\nno_stopwords = \"\" # this will contain the new string without any stop-words.\na = stopwords.words('english')\n\nfor i in sample:  # divide string and take one by one \n    if i not in a: # control each, if its not stop-words, include new string\n        no_stopwords += i\n    else:   # if its stop-words just pass \n        pass\n\nprint(sample) # print given example to compare with the new string which is without stop-words\nprint(no_stopwords)  # print new string","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}